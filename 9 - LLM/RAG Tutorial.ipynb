{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6035aea9",
   "metadata": {},
   "source": [
    "# 1 - Loading Documents --> PDF, Text, Webpage content, ...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9fbcf3",
   "metadata": {},
   "source": [
    "## Loading TextFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f202c039",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader('Path_Your Text file')\n",
    "text_documents = loader.load()\n",
    "text_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad317e6",
   "metadata": {},
   "source": [
    "## Web Documents Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6649f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "\n",
    "loader = WebBaseLoader(web_paths='https://lilianweng.github.io/posts/2024-07-07-hallucination/',\n",
    "                      bs_kwargs=dict(parse_only=bs4.SoupStrainer(\n",
    "                      class_=('post-title', 'post-content', 'post-header')\n",
    "                      )))\n",
    "text_documents = loader.load()\n",
    "text_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1855c90a",
   "metadata": {},
   "source": [
    "## PDF Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5122a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import bs4\n",
    "\n",
    "loader = PyPDFLoader('Path_Your PDF file')\n",
    "text_documents = loader.load()\n",
    "text_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6c0217",
   "metadata": {},
   "source": [
    "## PyPDFDirectoryLoader Folder Have PDF's Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e074f1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "import bs4\n",
    "\n",
    "loader = PyPDFDirectoryLoader(\"Path_Your Folder Have PDF's\")\n",
    "text_documents = loader.load()\n",
    "text_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7309ea4",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234e7321",
   "metadata": {},
   "source": [
    "# 2 - Splitting Data Into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420ab2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=400)\n",
    "documents = text_splitter.split_documents('Your Documents After Loading')\n",
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc695a1a",
   "metadata": {},
   "source": [
    "# 3 - Make Embeding OpenAI & Create VectorDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b228bf7e",
   "metadata": {},
   "source": [
    "## OpenAI Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33e9188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "\n",
    "db = Chroma.from_documents('Your Chunks', OpenAIEmbeddings())\n",
    "db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee2f781",
   "metadata": {},
   "source": [
    "## Ollama Embeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed90ac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "\n",
    "db = Chroma.from_documents('Your Chunks', OllamaEmbeddings())\n",
    "db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cde357",
   "metadata": {},
   "source": [
    "## Hugging-Face Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be3e154",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "vectordb = FAISS.from_documents('Your Chunks', HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\"))\n",
    "vectordb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd21caa",
   "metadata": {},
   "source": [
    "## GoogleGenerativeAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb9fdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectordb = FAISS.from_documents('Your Chunks', GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\"))\n",
    "vectordb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0459e84",
   "metadata": {},
   "source": [
    "## Create VectorDB Using Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d85da38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -qU \"langchain-chroma>=0.1.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05f6526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "\n",
    "db = Chroma.from_documents('Your Chunks', OpenAIEmbeddings())\n",
    "db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1b777e",
   "metadata": {},
   "source": [
    "## Create VectorDB Using FIASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a618fdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain-community faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0184ca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "\n",
    "db = FAISS.from_documents('Your Chunks', OpenAIEmbeddings())\n",
    "db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab32949",
   "metadata": {},
   "source": [
    "## Create VectorDB Using Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5c15ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain-pinecone pinecone-notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af015509",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "vector_store = PineconeVectorStore(index='Your Chunks', embedding=embeddings)\n",
    "vector_store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf9dde6",
   "metadata": {},
   "source": [
    "# 4 - Create a similarity retriever After Creating VectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def49e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Your Question'\n",
    "result = db.similarity_search(query)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75836ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c66617",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb12043",
   "metadata": {},
   "source": [
    "# 5 - LLM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd482bb",
   "metadata": {},
   "source": [
    "## Ollama Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0c0127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad06c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model='llama3.2')\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e10ca6",
   "metadata": {},
   "source": [
    "## OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e82b5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb25252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.llms import OpenAI\n",
    "llm = OpenAI(model='gpt-3.5-turbo')\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1067228",
   "metadata": {},
   "source": [
    "## Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5a25e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb95416",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.2-3b-preview\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3893af",
   "metadata": {},
   "source": [
    "## HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c92767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade --quiet  langchain-huggingface text-generation transformers google-search-results numexpr langchainhub sentencepiece jinja2 bitsandbytes accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ef51ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"HuggingFaceH4/zephyr-7b-beta\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=512,\n",
    "    do_sample=False,\n",
    "    repetition_penalty=1.03,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf795c2",
   "metadata": {},
   "source": [
    "## HuggingFace Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c48a56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"HuggingFaceH4/zephyr-7b-beta\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs=dict(\n",
    "        max_new_tokens=512,\n",
    "        do_sample=False,\n",
    "        repetition_penalty=1.03,\n",
    "    ),\n",
    ")\n",
    "\n",
    "chat_model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf73243",
   "metadata": {},
   "source": [
    "## VertixAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64bf636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain-google-vertexai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440a39e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import ChatVertexAI\n",
    "\n",
    "llm = ChatVertexAI(\n",
    "    model=\"gemini-1.5-flash-001\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    max_retries=6,\n",
    "    stop=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9601cce",
   "metadata": {},
   "source": [
    "## ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f655c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392c7fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f466bd3",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd188742",
   "metadata": {},
   "source": [
    "# 6 - Design Chat Prompt Templete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63c43ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    'Your Prompt Templete ...........'\n",
    ")\n",
    "\n",
    "Example_prompt = ChatPromptTemplate.from_template(\n",
    "    '''\n",
    "    Answer the following question based only on the provied context.\n",
    "    Think step by step before providing a details answer.\n",
    "    I will tip you 100$ if the user finds the answer helpful.\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "    Question: {input}\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b688036",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df3a18c",
   "metadata": {},
   "source": [
    "# 7 - Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b76e6a6",
   "metadata": {},
   "source": [
    "## 1 - Create  Stuff Document Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f727f9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "document_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98bc486",
   "metadata": {},
   "source": [
    "##### ......................\n",
    "##### ......................"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2479beb4",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376e49fd",
   "metadata": {},
   "source": [
    "# 8 - Create A retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67b0448",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriver = db.as_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d29aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever_chain = create_retrieval_chain(retriver, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1cc4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "respaonse = retriever_chain.invoke({'input': 'User Query'})\n",
    "respaonse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5ddc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "respaonse['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b7e244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd662e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35c28ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b017e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
